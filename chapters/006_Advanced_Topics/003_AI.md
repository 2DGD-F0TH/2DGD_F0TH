{{pagebreak}}

Artificial Intelligence in Videogames
======================================

:::::: {.epigraph author="Edsger W. Dijkstra"}
The question of whether a computer can think is no more interesting than the question of whether a submarine can swim.
::::::

In this part of the book we will take a look at some data structures and algorithms that will help you building your game's Artificial Intelligence.

Path Finding
-------------

Path Finding is that part of AI algorithms that takes care of getting from point A to point B, using the shortest way possible and avoiding obstacles.

### Representing our world

Before undertaking the concept of path finding algorithms, we need to decide in which way we should represent our world to the AI we want to code. There are different ways to do it and here we will discuss some of the most used ones.

#### 2D Grids

The simplest way to represent a world to an AI is probably using 2D grids: we can represent the world using a 2-dimensional matrix, where every cell is a free space, an obstacle, a start or goal cell.

This representation works well with top-down tile-based 2D games (with tile-based or free movement).

```{src='AI/2d_grid' caption='Possible representation of a 2D grid'}
```

Even though this is probably the most straightforward way to represent a world in many cases, most of the algorithms used work on a graph structure instead of a 2D grid. It shouldn't be too hard to adapt the algorithms presented here to work with this structure.

#### Path nodes

A more flexible way to represent our world is using "Path nodes", where each "path node" is represented by a node in a graph.

Graphs can be represented in code in two common ways (there are surely other ways to do so): using *adjacency lists* or using *adjacency matrices*.

This type of graph-based abstraction is the most used when teaching path finding algorithms like `A*` or `Dijkstra`.

##### Adjacency Lists

{{placeholder}}

<!-- TODO: Talk about adjacency lists for graphs -->

##### Adjacency Matrices

{{placeholder}}

<!-- TODO: Talk about adjacency matrices for graphs -->

#### Navigation meshes

Navigation meshes are used to solve a problem that can arise when we try to represent our world using path nodes: we can't represent "safe areas" (where the AI-driven entity can cross) without using possibly thousands of path nodes.

Navigation meshes are constituted by a collection of convex polygons (the meshes) that define the "safe areas", each mesh has no obstructions inside of itself, so the AI-driven entity can safely cross the entire mesh freely.

This abstraction allows to use `A*` and `Dijkstra` algorithms, but instead of trying to navigate a graph, you look for a path between meshes (which are saved in a graph structure).

To make the abstraction easier to understand, let's take a look at the following map.

![Map we will create a navigation mesh on [^jawbreaker]](./images/AI/nav_mesh1.png){width=60%}

The first step is to divide the map into convex polygons, in our case we will use rectangles.

![Dividing the map into many convex polygons [^jawbreaker]](./images/AI/nav_mesh2.png){width=60%}

Now each rectangle is a node of our graph (and will have to be treated accordingly by the AI, knowing it can navigate freely inside each rectangle), now we need to connect each node, following the limitations given by the walls.

![Creating the graph [^jawbreaker]](./images/AI/nav_mesh3.png){width=60%}

{{placeholder}}

<!-- TODO: Finish talking about navigation meshes -->

### Heuristics

In path finding there can be "heuristics" that are accounted for when you have to take a decision: in path finding an heuristic $h(x)$ is an estimated cost to travel from the current node to the goal node.

An heuristic is admissible if it *never overestimates* such cost: if it did, it wouldn't guarantee that the algorithm would find the best path to the goal node.

In this book we will present the most common heuristics used in game development.

#### Manhattan Distance heuristic

The Manhattan Distance heuristic doesn't allow diagonal movement (allowing it would allow the heuristic to overestimate the cost), and for a 2D grid is formulated as follows:

$$ h(x) = | start.x - goal.x | + | start.y - goal.y | $$

Graphically:

![Example of Manhattan distance](./images/AI/manhattan_distance.png){width=60%}

On the left we can see how we calculate the Manhattan distance, on the right you can notice how all the "possibly shortest" alternative paths have the same Manhattan distance.

Since all "possibly shortest" paths between two points have the same Manhattan distance, this guarantees us that the algorithm will never overestimate (all the other paths will be longer, so the Manhattan distance will underestimate the cost), which is required for this heuristic to be considered "admissible".

```{src='AI/manhattan_distance' caption='Example code calculating the Manhattan distance on a 2D grid'}
```

This works well with 2D grid-based worlds.

#### Euclidean Distance heuristic

Euclidean Distance works well when diagonal movement in a 2D grid is allowed, Euclidean distance is calculated with the standard distance formula:

$$ h(x) = \sqrt{(start.x - end.x) ^2 + (start.y - end.y)^2}$$

![Example of Euclidean Distance](./images/AI/euclidean_distance.png){width=30%}

```{src='AI/euclidean_distance' caption='Example code calculating the Euclidean distance on a 2D grid'}
```

### Algorithms

Before getting to the algorithms, we need to consider two supporting data structures that we will use:

- **Open Set:** a sorted data structure that contains the nodes that currently need to be considered. It should be an heap or any kind of structure that can be quickly be sorted as we will have to often refer to the node/cell/mesh with the lowest heuristic.
- **Closed Set:** a data structure that will contain all the nodes/meshes/cells that have already been considered by the algorithm. This structure should be easily searchable (like a binary search tree), since we will often need to see if a certain node/cell/mesh is part of this set.

We will reference this image when we check what path the algorithm will take:

![Pathfinding Algorithms Reference Image](./images/AI/pathfinding_reference.png){width=30%}

The shaded rows represent the indexes we'll refer to when operating the algorithm.

In each algorithm there will be the path taken by its implementation, so we invite you to execute the algorithm's instructions by hand, taking account of the heuristics pre-calculated and shown in the images below.

![Pathfinding Algorithms Heuristics Reference Image](./images/AI/pathfinding_heuristics.png){width=60%}

#### A simple "Wandering" Algorithm

This is not a real "pathfinding" algorithm, as much as something that should give the impression of people "wandering around". This algorithm is really simple and can be summarized in 2 rules:

1. Choose one direction at random, if you can't go that way continue your search clockwise;
2. You cannot go back, unless it's the only direction available.

This is good when used on mazes, let's try an example:

![Simple wandering algorithm 1/2](./images/AI/wandering_1.png){width=50%}

In this case, our random choice is forwards, but that leads us to a wall, so we continue our search clockwise:

![Simple wandering algorithm 2/2](./images/AI/wandering_2.png){width=50%}

After going clockwise once, we hit another wall, so we continue, this direction is good, but it would lead us backwards, so we ignore it. The only direction possible is left.

This algorithm is far from perfect: if we build a very simple maze, we can break the algorithm:

![This maze breaks our wandering algorithm](./images/AI/wandering_broken.png){width=50%}

If you calculate the probabilities, you can see that starting from the entrance, the AI has a 75% chance of going into one of those alcoves and only a 25% chance of going forwards.

This means that an entity has only a $25\%^6=0.0244\%$ chance of finishing the maze without ever turning left. Not only that, but every time the entity exits an alcove, it has a 50% chance of turning either direction (turning left means going forwards, going right means going backwards), which means that there is a 37.5% chance (75% chance turning left and 50% turning right) that the entity will go back towards the entrance of our maze.

Let's see a possible implementation of this algorithm.

```{src='AI/wandering' caption='Implementation of a simple wandering algorithm'}
```

#### A slightly better "Wandering" algorithm

As we have seen, the previous wandering algorithm has a very heavy bias, let's plan for another algorithm that works a bit better and has a lower bias.

1. Check for all valid directions around you.
2. If no valid direction is found, go back.
3. If at least one valid direction is found, choose a random one between the valid directions found.

This algorithm relies on the fact that randomly selecting an item from a list containing a single item will return that single item in 100% of the cases.

Let's see a code implementation of such algorithm.

```{src='AI/wandering_2' caption='Implementation of a better wandering algorithm'}
```

This algorithm chooses between all available directions with the same probability, and has a minor bias towards going to the maze entrance.

#### The Greedy "Best First" Algorithm

This is a *greedy algorithm*~[g]~ that searches the "local best" (what is best in a certain moment, without planning future decisions) that makes use of heuristics.

For each of the neighbouring cells/meshes/nodes that have not been explored yet, the algorithm will take the one that has the lowest heuristic cost. Since this algorithm doesn't make any planning, this can lead to results that are not optimal, usually translating in entities hugging walls to reach their goal, as well as taking longer paths.

In this algorithm we will use a "Node" structure composed as follows:

```{src='AI/greedy_node_structure' caption='The node structure used in the greedy "Best First" algorithm'}
```

Let's look at the algorithm itself:

```{src='AI/greedy_best_first' caption='The greedy "Best First" algorithm'}
```

An interesting idea to optimize this algorithm and avoid the final "stack reversal" would be to find the path starting from the end node, towards the starting node.

In the image below we can see the path taken by the algorithm, and how it is not the most optimal path.

![The path taken by the greedy "Best First" algorithm](./images/AI/greedy_best_first_path.png){width=30%}

#### The Dijkstra Algorithm

The idea behind the Dijkstra algorithm is having a "cost" component that expresses the cost that has to be incurred when traveling from the start node to the current node. This will allow our previous algorithm to evolve and take the shortest path possible.

To be able to keep track of such "path-cost" component, we will use a different "Node" structure from the one used in the greedy "best-first" algorithm:

```{src='AI/dijkstra_node_structure' caption='The node structure used in the Dijkstra Algorithm'}
```

The idea behind the whole algorithm is that "if we find a quicker way to get from the start node to the current node, we should take it".

Let's take a look at the algorithm:

```{src='AI/dijkstra' caption='The Dijkstra Algorithm'}
```

As with the greedy "best-first" algorithm we can optimize the "stack reversal" stage by starting from the end node.

Below we can see the path taken by the algorithm:

![The path taken by the Dijkstra Algorithm](./images/AI/dijkstra_path.png){width=30%}

#### The A* Algorithm

The A* Algorithm joins the "path-cost" idea with the heuristic to have a more efficient path-finding algorithm.

The algorithm is really similar to Dijkstra, but it orders the open set by a new formula $f$, that is calculated as follows:

$$ f(x) = g(x) + h(x)$$

Where $g(x)$ is our path cost and $h(x)$ is the heuristic we selected.

Let's see the code:

```{src='AI/a_star' caption='The A* Algorithm'}
```

The path taken by the A* Algorithm is exactly the same as the one taken by the Dijkstra Algorithm, but the heuristic helps the A* Algorithm in visiting less nodes than its counterpart.

##### Dijkstra Algorithm as a special case of the A* Algorithm

The Dijkstra Algorithm can be implemented with the same code as the A* Algorithm, just by keeping the heuristic cost $h(x) = 0$.

The absence of the heuristics (which depends on the goal node) leads the Dijkstra Algorithm to visit more nodes, but it can be useful in case there are many valid goal nodes and we don't know which one is the closest.

Finite state machines
----------------------

We can use finite state machines, introduced previously, to define some quite complex Artificial Intelligence schemes.

![Finite state machine representing an enemy AI](./images/AI/finite_state_machine.svg){width=60%}

We can see in the previous image how we can use conditions as transition between different "states of mind" of our enemy AI, making it act differently.

The enemy will be patrolling by default, but if the player is heard or seen the enemy will enter its "alert state", where it will either call for backup or actively search for the player. As soon as the player is found, the enemy will attack and try to kill the player.

Decision Trees
--------------

Decision trees are a structure used to define the decision process of an AI-controlled entity.

![Example of a decision tree](./images/AI/Decision_Tree.svg){width=60%}

Decision trees are always evaluated from root to leaf, and each node represents a condition that can be more or less complex. In the image above we used a simple "binary tree" to represent conditions that can be answered with "yes" or "no".

{{placeholder}}

<!-- TODO: Talk about decision trees and how they can be used to build primitive/simple AIs -->

Behaviour Trees
----------------

Similar in structure to Decision Trees, *Behaviour Trees* are different in their evaluation.

![Example of a behaviour tree](./images/AI/Behaviour_Tree.svg){width=60%}

First of all, the child nodes of a behaviour tree are ordered by priority, if a child node has all of its conditions met its internal state is changed to "running" and the chosen "behaviour" is returned to the caller.

The next evaluation, the tree is again evaluated, in order, if a "running" node is met, such behaviour will continue to persist for the current frame. In case a "higher priority" behaviour is met, that one behaviour will start running (instead of the behaviour chosen earlier).

In case a node doesn't have all of its conditions met, the algorithm will return to the parent node, which will chose the next node, in priority order.

{{placeholder}}
<!-- TODO: Talk about behaviour trees and how they are different from decision trees and can be used to model more complex AIs -->
